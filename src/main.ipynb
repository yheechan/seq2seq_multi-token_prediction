{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_list = [\n",
    "    'boringssl', 'c-ares',\n",
    "    'freetype2', 'guetzli',\n",
    "    'harfbuzz', 'lcms',\n",
    "    'libpng', 'libssh',\n",
    "    'libxml2', 'pcre2',\n",
    "    'proj4', 're2',\n",
    "    'sqlite3', 'vorbis',\n",
    "    'woff2', 'wpantund'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_project = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch, gc\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import timeit\n",
    "\n",
    "import data\n",
    "import data_loader as dl\n",
    "import initializer as init\n",
    "import trainer\n",
    "import tester\n",
    "# import predictor\n",
    "import model_util as mu\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for \"boringssl\" from \"boringssl\"\n",
      "Getting data for \"boringssl\" from \"c-ares\"\n",
      "Getting data for \"boringssl\" from \"freetype2\"\n",
      "Getting data for \"boringssl\" from \"guetzli\"\n",
      "Getting data for \"boringssl\" from \"harfbuzz\"\n",
      "Getting data for \"boringssl\" from \"lcms\"\n",
      "Getting data for \"boringssl\" from \"libpng\"\n",
      "Getting data for \"boringssl\" from \"libssh\"\n",
      "Getting data for \"boringssl\" from \"libxml2\"\n",
      "Getting data for \"boringssl\" from \"pcre2\"\n",
      "Getting data for \"boringssl\" from \"proj4\"\n",
      "Getting data for \"boringssl\" from \"re2\"\n",
      "Getting data for \"boringssl\" from \"sqlite3\"\n",
      "Getting data for \"boringssl\" from \"vorbis\"\n",
      "Getting data for \"boringssl\" from \"woff2\"\n",
      "Getting data for \"boringssl\" from \"wpantund\"\n"
     ]
    }
   ],
   "source": [
    "# get all data exept target project\n",
    "prefix_np, postfix_np, label_np, label_len_np = data.getTrainData(proj_list, proj_list[target_project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target project data\n",
    "test_prefix, test_postfix, test_label, test_label_len = data.getTestData(proj_list[target_project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix, val_prefix, train_postfix, val_postfix, train_label, val_label = train_test_split(\n",
    "    prefix_np, postfix_np, label_np, test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader =\\\n",
    "    dl.data_loader(\n",
    "        train_prefix, train_postfix,\n",
    "        val_prefix, val_postfix,\n",
    "        test_prefix, test_postfix,\n",
    "        train_label, val_label, test_label,\n",
    "        batch_size=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_title = 'webModel2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('../tensorboard/'+overall_title+'/tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# set parameters here\n",
    "# ====================\n",
    "\n",
    "title = proj_list[target_project] + '_' + overall_title + '_1'\n",
    "epochs = 40\n",
    "\n",
    "max_len, source_code_tokens, token_choices = data.getInfo()\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4 \n",
    "\n",
    "embed_dim = 100\n",
    "hidden_size = 200\n",
    "n_layers = 1\n",
    "output_size = max(token_choices) + 1\n",
    "dropout = 0.5\n",
    "max_length = max_len\n",
    "input_size = max(token_choices) + 1\n",
    "device = device\n",
    "\n",
    "model_name = \"seq2seq\"\n",
    "optim_name = \"Adam\"\n",
    "loss_fn_name = \"CEL\"\n",
    "\n",
    "teacher_forcing_ratio = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arise/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "trainer.set_seed(42)\n",
    "\n",
    "loss_fn, prefix_pack, postfix_pack, attn_pack = init.initialize_model(\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    n_layers=n_layers,\n",
    "    output_size=output_size,\n",
    "    dropout=dropout,\n",
    "    max_length=max_length,\n",
    "    input_size=input_size,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  | Train Acc  | Val Loss | Val Acc | Elapsed\n",
      "--------------------------------------------------------------------------------\n",
      "   1    |   5.899568   | 95.471813  | 7.187643 | 94.31  | 296.78\n",
      "   2    |   5.162465   | 97.476540  | 6.972044 | 94.88  | 291.78\n",
      "   3    |   5.097184   | 97.685194  | 6.884520 | 95.10  | 290.83\n",
      "   4    |   5.062872   | 97.793354  | 6.851388 | 95.25  | 288.12\n",
      "   5    |   5.040807   | 97.870968  | 6.777013 | 95.31  | 277.42\n",
      "   6    |   5.023172   | 97.934692  | 6.807281 | 95.37  | 281.59\n",
      "   7    |   5.010994   | 97.972518  | 6.776111 | 95.47  | 280.70\n",
      "   8    |   4.999697   | 98.016479  | 6.769220 | 95.53  | 278.19\n",
      "   9    |   4.990455   | 98.046505  | 6.680728 | 95.61  | 279.07\n",
      "  10    |   4.983181   | 98.078785  | 6.700008 | 95.66  | 279.65\n",
      "  11    |   4.976300   | 98.099833  | 6.612866 | 95.71  | 278.13\n",
      "  12    |   4.970039   | 98.125502  | 6.665937 | 95.77  | 281.81\n",
      "  13    |   4.963889   | 98.149296  | 6.650306 | 95.78  | 277.59\n",
      "  14    |   4.958893   | 98.167879  | 6.596799 | 95.80  | 281.17\n",
      "  15    |   4.953721   | 98.187227  | 6.652396 | 95.85  | 278.01\n",
      "  16    |   4.949925   | 98.201206  | 6.604120 | 95.82  | 281.39\n",
      "  17    |   4.945194   | 98.218468  | 6.519769 | 95.94  | 274.73\n",
      "  18    |   4.941860   | 98.232412  | 6.579011 | 95.86  | 280.54\n",
      "  19    |   4.938931   | 98.243952  | 6.574868 | 95.85  | 279.87\n",
      "  20    |   4.935758   | 98.258785  | 6.557116 | 95.94  | 274.37\n",
      "  21    |   4.932429   | 98.268732  | 6.599755 | 95.96  | 281.91\n",
      "  22    |   4.929872   | 98.283609  | 6.595529 | 95.97  | 280.21\n",
      "  23    |   4.927546   | 98.287958  | 6.507801 | 95.97  | 280.75\n",
      "  24    |   4.924874   | 98.301320  | 6.552147 | 96.00  | 278.88\n",
      "  25    |   4.922547   | 98.309208  | 6.517000 | 96.01  | 280.69\n",
      "  26    |   4.919567   | 98.325546  | 6.529718 | 96.03  | 278.26\n",
      "  27    |   4.918040   | 98.326391  | 6.507218 | 96.03  | 279.07\n",
      "  28    |   4.915345   | 98.338090  | 6.463835 | 96.08  | 281.80\n",
      "  29    |   4.914170   | 98.343504  | 6.449071 | 96.08  | 274.20\n",
      "  30    |   4.912324   | 98.350792  | 6.539323 | 96.05  | 281.45\n",
      "  31    |   4.910218   | 98.359305  | 6.502750 | 96.11  | 279.36\n",
      "  32    |   4.908430   | 98.365792  | 6.470789 | 96.04  | 279.56\n",
      "  33    |   4.907540   | 98.368442  | 6.459661 | 96.06  | 280.44\n",
      "  34    |   4.905058   | 98.381188  | 6.502063 | 96.10  | 279.53\n",
      "  35    |   4.904015   | 98.385687  | 6.483284 | 96.11  | 283.06\n",
      "  36    |   4.901557   | 98.397280  | 6.456103 | 96.08  | 279.11\n",
      "  37    |   4.900103   | 98.402201  | 6.435452 | 96.18  | 281.06\n",
      "  38    |   4.899933   | 98.404111  | 6.468528 | 96.10  | 278.55\n",
      "  39    |   4.897649   | 98.409076  | 6.458872 | 96.11  | 281.25\n",
      "  40    |   4.896377   | 98.415273  | 6.418953 | 96.15  | 277.69\n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 96.18%.\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "trainer.train(\n",
    "    epochs=epochs,\n",
    "    title=title,\n",
    "    writer=writer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn,\n",
    "    prefix_pack=prefix_pack,\n",
    "    postfix_pack=postfix_pack,\n",
    "    attn_pack=attn_pack,\n",
    "    teacher_forcing_ratio=teacher_forcing_ratio\n",
    ")\n",
    "\n",
    "end_time = (timeit.default_timer() - start_time) / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.saveModel(overall_title, title, prefix_pack, postfix_pack, attn_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_pack, postfix_pack, attn_pack = mu.getModel(overall_title, title)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  6.463136776154028\n",
      "test acc:  96.03128404669262\n"
     ]
    }
   ],
   "source": [
    "loss, acc = tester.test(\n",
    "    test_dataloader=test_dataloader,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn,\n",
    "    prefix_pack=prefix_pack,\n",
    "    postfix_pack=postfix_pack,\n",
    "    attn_pack=attn_pack\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stat/'+overall_title, 'a') as f:\n",
    "        text = title + '\\t |\\tloss: ' + str(loss) + '\\t |\\tacc: ' + str(acc) + '\\t |\\t time: ' + str(round(end_time, 3)) + ' min\\n'\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu.graphModel(train_dataloader, model, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
