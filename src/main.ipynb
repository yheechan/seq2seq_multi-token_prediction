{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version2\n",
    "proj_list = [\n",
    "    'boringssl', 'c-ares',\n",
    "    'freetype2', 'guetzli',\n",
    "    'harfbuzz', 'lcms',\n",
    "    'libarchive', 'libpng',\n",
    "    'libssh', 'libxml2',\n",
    "    'pcre2', 'proj4',\n",
    "    're2', 'sqlite3',\n",
    "    'vorbis', 'woff2',\n",
    "    'wpantund'\n",
    "]\n",
    "\n",
    "# version3\n",
    "proj_list = [\n",
    "    'boringssl', 'c-ares',\n",
    "    'freetype2', 'guetzli',\n",
    "    'harfbuzz', 'lcms',\n",
    "    'libpng', 'libssh',\n",
    "    'libxml2', 'pcre2',\n",
    "    'proj4', 're2',\n",
    "    'sqlite3', 'vorbis',\n",
    "    'woff2', 'wpantund'\n",
    "]\n",
    "\n",
    "version = 'version4'\n",
    "proj_list = [\n",
    "    'total_aspell', 'total_boringssl', 'total_c-ares', 'total_exiv2',\n",
    "    'total_freetype2', 'total_grok', 'total_guetzli', 'total_harfbuzz',\n",
    "    'total_lcms', 'total_libarchive', 'total_libexif', 'total_libhtp',\n",
    "    'total_libpng', 'total_libsndfile', 'total_libssh', 'total_libxml2',\n",
    "    'total_ndpi', 'total_openthread', 'total_pcre2', 'total_proj4',\n",
    "    'total_re2', 'total_sqlite3', 'total_usrsctp', 'total_vorbis',\n",
    "    'total_woff2', 'total_wpantund', 'total_yara', 'total_zstd'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_project = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch, gc\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import timeit\n",
    "\n",
    "import data\n",
    "import data_loader as dl\n",
    "import initializer as init\n",
    "import trainer\n",
    "import tester\n",
    "# import predictor\n",
    "import model_util as mu\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for \"total_aspell\" from \"total_aspell\"\n"
     ]
    }
   ],
   "source": [
    "# get all data exept target project\n",
    "prefix_np, postfix_np, label_np, label_len_np = data.getTrainData(proj_list, proj_list[target_project], version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target project data\n",
    "# test_prefix, test_postfix, test_label, test_label_len = data.getTestData(proj_list[target_project], version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide train & test\n",
    "train_prefix, test_prefix, train_postfix, test_postfix, train_label, test_label = train_test_split(\n",
    "    prefix_np, postfix_np, label_np, test_size = 0.2, random_state = 43\n",
    ")\n",
    "\n",
    "# divide train & validation\n",
    "train_prefix, val_prefix, train_postfix, val_postfix, train_label, val_label = train_test_split(\n",
    "    train_prefix, train_postfix, train_label, test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  16770\n",
      "train:  53663\n",
      "validation:  13416\n"
     ]
    }
   ],
   "source": [
    "print('test: ', len(test_label))\n",
    "print('train: ', len(train_label))\n",
    "print('validation: ', len(val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader =\\\n",
    "    dl.data_loader(\n",
    "        train_prefix, train_postfix,\n",
    "        val_prefix, val_postfix,\n",
    "        test_prefix, test_postfix,\n",
    "        train_label, val_label, test_label,\n",
    "        batch_size=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_title = 'version3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('../tensorboard/'+overall_title+'/tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# set parameters here\n",
    "# ====================\n",
    "\n",
    "title = overall_title + '_01'\n",
    "epochs = 40\n",
    "\n",
    "max_len, source_code_tokens, token_choices = data.getInfo()\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0\n",
    "\n",
    "embed_dim = 100\n",
    "hidden_size = 200\n",
    "n_layers = 1\n",
    "output_size = max(token_choices) + 1\n",
    "dropout = 0.0\n",
    "max_length = max_len\n",
    "input_size = max(token_choices) + 1\n",
    "device = device\n",
    "\n",
    "model_name = \"seq2seq\"\n",
    "optim_name = \"Adam\"\n",
    "loss_fn_name = \"CEL\"\n",
    "\n",
    "teacher_forcing_ratio = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_seed(42)\n",
    "\n",
    "model, loss_fn, optimizer = init.initialize_model(\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    n_layers=n_layers,\n",
    "    output_size=output_size,\n",
    "    dropout=dropout,\n",
    "    max_length=max_length,\n",
    "    input_size=input_size,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  | Train Acc  | Val Loss | Val Acc | Elapsed\n",
      "--------------------------------------------------------------------------------\n",
      "   1    |   1.308302   | 76.840755  | 0.901219 | 80.27  | 16.79 \n",
      "   2    |   0.684222   | 81.998113  | 0.830487 | 80.27  | 16.75 \n",
      "   3    |   0.629433   | 83.063019  | 0.838897 | 80.31  | 16.66 \n",
      "   4    |   0.597073   | 84.273019  | 0.803433 | 79.79  | 16.62 \n",
      "   5    |   0.537569   | 86.316415  | 0.653841 | 83.08  | 16.52 \n",
      "   6    |   0.465508   | 87.894906  | 0.671366 | 83.10  | 16.54 \n",
      "   7    |   0.425841   | 88.824151  | 0.558472 | 85.33  | 16.51 \n",
      "   8    |   0.363078   | 90.279245  | 0.588315 | 85.55  | 16.46 \n",
      "   9    |   0.357175   | 90.405094  | 0.504961 | 87.02  | 16.54 \n",
      "  10    |   0.310093   | 91.510000  | 0.501003 | 87.24  | 16.48 \n",
      "  11    |   0.303981   | 91.840755  | 0.468243 | 88.05  | 16.42 \n",
      "  12    |   0.287610   | 92.291887  | 0.441862 | 88.41  | 16.56 \n",
      "  13    |   0.282550   | 92.485094  | 0.423585 | 89.30  | 16.92 \n",
      "  14    |   0.247601   | 93.364528  | 0.417381 | 89.83  | 16.84 \n",
      "  15    |   0.261117   | 93.094151  | 0.394892 | 90.25  | 16.37 \n",
      "  16    |   0.224757   | 94.012264  | 0.401303 | 90.43  | 16.39 \n",
      "  17    |   0.210232   | 94.423396  | 0.366139 | 90.79  | 16.39 \n",
      "  18    |   0.183548   | 95.013585  | 0.406087 | 90.96  | 16.27 \n",
      "  19    |   0.204305   | 94.688113  | 0.359412 | 91.30  | 16.35 \n",
      "  20    |   0.184527   | 95.132642  | 0.346350 | 91.57  | 16.17 \n",
      "  21    |   0.203266   | 94.788868  | 0.328604 | 91.65  | 16.90 \n",
      "  22    |   0.165642   | 95.668302  | 0.331719 | 92.00  | 16.44 \n",
      "  23    |   0.182987   | 95.335472  | 0.315643 | 92.18  | 17.17 \n",
      "  24    |   0.169419   | 95.662264  | 0.321970 | 91.94  | 16.98 \n",
      "  25    |   0.151293   | 96.060943  | 0.322456 | 92.41  | 16.72 \n",
      "  26    |   0.147643   | 96.218868  | 0.317466 | 92.67  | 16.44 \n",
      "  27    |   0.143303   | 96.366038  | 0.324306 | 92.31  | 16.36 \n",
      "  28    |   0.149388   | 96.200189  | 0.287291 | 92.92  | 16.64 \n",
      "  29    |   0.124308   | 96.807170  | 0.310482 | 93.16  | 16.80 \n",
      "  30    |   0.123181   | 96.886038  | 0.318250 | 93.07  | 16.50 \n",
      "  31    |   0.120341   | 96.992642  | 0.285832 | 93.48  | 16.39 \n",
      "  32    |   0.119586   | 97.028113  | 0.284849 | 93.52  | 17.44 \n",
      "  33    |   0.107706   | 97.336604  | 0.277829 | 93.78  | 17.35 \n",
      "  34    |   0.102738   | 97.434717  | 0.296708 | 93.72  | 17.11 \n",
      "  35    |   0.096426   | 97.634717  | 0.279086 | 93.85  | 17.25 \n",
      "  36    |   0.096178   | 97.664906  | 0.276757 | 93.94  | 17.22 \n",
      "  37    |   0.080567   | 98.023585  | 0.285746 | 94.01  | 17.25 \n",
      "  38    |   0.101758   | 97.607925  | 0.267320 | 93.90  | 17.51 \n",
      "  39    |   0.081302   | 98.027170  | 0.273431 | 94.30  | 17.10 \n",
      "  40    |   0.079044   | 98.127358  | 0.266756 | 94.28  | 17.08 \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 94.30%.\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "trainer.train(\n",
    "    epochs=epochs,\n",
    "    title=title,\n",
    "    writer=writer,\n",
    "    teacher_forcing_ratio=teacher_forcing_ratio,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "end_time = (timeit.default_timer() - start_time) / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.saveModel(overall_title, title, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySeq2Seq(\n",
      "  (prefixEncoder): Encoder(\n",
      "    (embedding): Embedding(155, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postfixEncoder): Encoder(\n",
      "    (embedding): Embedding(155, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(155, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attn): Attention(\n",
      "    (fc): Linear(in_features=800, out_features=155, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = mu.getModel(overall_title, title)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  0.2838988053961657\n",
      "test acc:  93.88562499999999\n"
     ]
    }
   ],
   "source": [
    "loss, acc = tester.test(\n",
    "    test_dataloader=test_dataloader,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stat/'+overall_title, 'a') as f:\n",
    "        text = title + '\\t |\\tloss: ' + str(loss) + '\\t |\\tacc: ' + str(acc) + '\\t |\\t time: ' + str(round(end_time, 3)) + ' min\\n'\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded model graph to tensorboard!\n"
     ]
    }
   ],
   "source": [
    "mu.graphModel(train_dataloader, model, writer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
