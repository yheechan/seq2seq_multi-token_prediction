{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_list = [\n",
    "    'boringssl', 'c-ares',\n",
    "    'freetype2', 'guetzli',\n",
    "    'harfbuzz', 'lcms',\n",
    "    'libpng', 'libssh',\n",
    "    'libxml2', 'pcre2',\n",
    "    'proj4', 're2',\n",
    "    'sqlite3', 'vorbis',\n",
    "    'woff2', 'wpantund'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_project = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch, gc\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import timeit\n",
    "\n",
    "import data\n",
    "import data_loader as dl\n",
    "import initializer as init\n",
    "import trainer\n",
    "import tester\n",
    "# import predictor\n",
    "import model_util as mu\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for \"boringssl\" from \"boringssl\"\n",
      "Getting data for \"boringssl\" from \"c-ares\"\n",
      "Getting data for \"boringssl\" from \"freetype2\"\n",
      "Getting data for \"boringssl\" from \"guetzli\"\n",
      "Getting data for \"boringssl\" from \"harfbuzz\"\n",
      "Getting data for \"boringssl\" from \"lcms\"\n",
      "Getting data for \"boringssl\" from \"libpng\"\n",
      "Getting data for \"boringssl\" from \"libssh\"\n",
      "Getting data for \"boringssl\" from \"libxml2\"\n",
      "Getting data for \"boringssl\" from \"pcre2\"\n",
      "Getting data for \"boringssl\" from \"proj4\"\n",
      "Getting data for \"boringssl\" from \"re2\"\n",
      "Getting data for \"boringssl\" from \"sqlite3\"\n",
      "Getting data for \"boringssl\" from \"vorbis\"\n",
      "Getting data for \"boringssl\" from \"woff2\"\n",
      "Getting data for \"boringssl\" from \"wpantund\"\n"
     ]
    }
   ],
   "source": [
    "# get all data exept target project\n",
    "prefix_np, postfix_np, label_np, label_len_np = data.getTrainData(proj_list, proj_list[target_project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target project data\n",
    "test_prefix, test_postfix, test_label, test_label_len = data.getTestData(proj_list[target_project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix, val_prefix, train_postfix, val_postfix, train_label, val_label = train_test_split(\n",
    "    prefix_np, postfix_np, label_np, test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader =\\\n",
    "    dl.data_loader(\n",
    "        train_prefix, train_postfix,\n",
    "        val_prefix, val_postfix,\n",
    "        test_prefix, test_postfix,\n",
    "        train_label, val_label, test_label,\n",
    "        batch_size=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_title = 'webModel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('../tensorboard/'+overall_title+'/tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# set parameters here\n",
    "# ====================\n",
    "\n",
    "title = proj_list[target_project] + '_' + overall_title + '_all'\n",
    "epochs = 40\n",
    "\n",
    "max_len, source_code_tokens, token_choices = data.getInfo()\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4 \n",
    "\n",
    "embed_dim = 100\n",
    "hidden_size = 200\n",
    "n_layers = 1\n",
    "output_size = max(token_choices) + 1\n",
    "dropout = 0.5\n",
    "max_length = max_len\n",
    "input_size = max(token_choices) + 1\n",
    "device = device\n",
    "\n",
    "model_name = \"seq2seq\"\n",
    "optim_name = \"Adam\"\n",
    "loss_fn_name = \"CEL\"\n",
    "\n",
    "teacher_forcing_ratio = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arise/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "trainer.set_seed(42)\n",
    "\n",
    "loss_fn, prefix_pack, postfix_pack, attn_pack = init.initialize_model(\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    n_layers=n_layers,\n",
    "    output_size=output_size,\n",
    "    dropout=dropout,\n",
    "    max_length=max_length,\n",
    "    input_size=input_size,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  | Train Acc  | Val Loss | Val Acc | Elapsed\n",
      "--------------------------------------------------------------------------------\n",
      "   1    |   6.552861   | 95.523052  | 10.254885 | 91.10  | 257.12\n",
      "   2    |   5.869176   | 97.099427  | 9.985193 | 92.07  | 255.66\n",
      "   3    |   5.777104   | 97.372450  | 9.839251 | 92.56  | 254.31\n",
      "   4    |   5.728923   | 97.522842  | 9.640662 | 92.98  | 254.30\n",
      "   5    |   5.697606   | 97.621887  | 9.714430 | 93.09  | 252.53\n",
      "   6    |   5.675050   | 97.696113  | 9.630375 | 93.18  | 250.09\n",
      "   7    |   5.656319   | 97.760838  | 9.585769 | 93.28  | 254.26\n",
      "   8    |   5.641988   | 97.804230  | 9.590503 | 93.21  | 248.81\n",
      "   9    |   5.629625   | 97.845540  | 9.515908 | 93.51  | 252.59\n",
      "  10    |   5.617276   | 97.886870  | 9.447333 | 93.63  | 268.54\n",
      "  11    |   5.606930   | 97.919939  | 9.477017 | 93.58  | 268.15\n",
      "  12    |   5.598034   | 97.949981  | 9.350319 | 93.72  | 257.20\n",
      "  13    |   5.587972   | 97.984931  | 9.398254 | 93.81  | 254.89\n",
      "  14    |   5.579385   | 98.013245  | 9.483922 | 93.81  | 249.79\n",
      "  15    |   5.573211   | 98.038627  | 9.373765 | 93.97  | 255.18\n",
      "  16    |   5.564990   | 98.057372  | 9.307196 | 93.97  | 250.02\n",
      "  17    |   5.557325   | 98.090327  | 9.513454 | 93.97  | 252.03\n",
      "  18    |   5.550278   | 98.112538  | 9.396221 | 94.04  | 253.32\n",
      "  19    |   5.545301   | 98.128619  | 9.318791 | 94.08  | 248.73\n",
      "  20    |   5.539167   | 98.150277  | 9.260466 | 94.11  | 252.87\n",
      "  21    |   5.533358   | 98.169146  | 9.368330 | 94.18  | 253.86\n",
      "  22    |   5.527790   | 98.187586  | 9.257880 | 94.07  | 249.39\n",
      "  23    |   5.522308   | 98.211602  | 9.227466 | 94.27  | 254.70\n",
      "  24    |   5.516577   | 98.229402  | 9.199938 | 94.26  | 247.95\n",
      "  25    |   5.512917   | 98.240728  | 9.280008 | 94.25  | 229.30\n",
      "  26    |   5.507206   | 98.258909  | 9.096113 | 94.25  | 229.12\n",
      "  27    |   5.503248   | 98.274819  | 9.110166 | 94.36  | 229.14\n",
      "  28    |   5.498678   | 98.290451  | 9.145886 | 94.41  | 229.13\n",
      "  29    |   5.495561   | 98.298816  | 9.111059 | 94.42  | 229.24\n",
      "  30    |   5.490962   | 98.315508  | 9.092045 | 94.45  | 229.27\n",
      "  31    |   5.486263   | 98.333795  | 9.050024 | 94.55  | 229.16\n",
      "  32    |   5.482995   | 98.344414  | 9.037954 | 94.48  | 229.20\n",
      "  33    |   5.480037   | 98.354947  | 9.150857 | 94.47  | 229.12\n",
      "  34    |   5.475729   | 98.367265  | 8.989956 | 94.55  | 229.06\n",
      "  35    |   5.471972   | 98.381627  | 9.008195 | 94.52  | 228.96\n",
      "  36    |   5.469090   | 98.391558  | 8.989033 | 94.56  | 228.92\n",
      "  37    |   5.466601   | 98.398940  | 9.009808 | 94.51  | 229.22\n",
      "  38    |   5.462830   | 98.415126  | 8.957689 | 94.69  | 229.11\n",
      "  39    |   5.460267   | 98.420674  | 8.958073 | 94.62  | 229.20\n",
      "  40    |   5.457552   | 98.431379  | 8.971319 | 94.63  | 229.14\n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 94.69%.\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "trainer.train(\n",
    "    epochs=epochs,\n",
    "    title=title,\n",
    "    writer=writer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn,\n",
    "    prefix_pack=prefix_pack,\n",
    "    postfix_pack=postfix_pack,\n",
    "    attn_pack=attn_pack,\n",
    "    teacher_forcing_ratio=teacher_forcing_ratio\n",
    ")\n",
    "\n",
    "end_time = (timeit.default_timer() - start_time) / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.saveModel(overall_title, title, prefix_pack, postfix_pack, attn_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_pack, postfix_pack, attn_pack = mu.getModel(overall_title, title)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  8.657929990149384\n",
      "test acc:  95.01149628581535\n"
     ]
    }
   ],
   "source": [
    "loss, acc = tester.test(\n",
    "    test_dataloader=test_dataloader,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn,\n",
    "    prefix_pack=prefix_pack,\n",
    "    postfix_pack=postfix_pack,\n",
    "    attn_pack=attn_pack\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stat/'+overall_title, 'a') as f:\n",
    "        text = title + '\\t |\\tloss: ' + str(loss) + '\\t |\\tacc: ' + str(acc) + '\\t |\\t time: ' + str(round(end_time, 3)) + ' min\\n'\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu.graphModel(train_dataloader, model, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
