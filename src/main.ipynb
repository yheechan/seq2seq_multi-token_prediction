{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_list = [\n",
    "    'boringssl', 'c-ares',\n",
    "    'freetype2', 'guetzli',\n",
    "    'harfbuzz', 'lcms',\n",
    "    'libpng', 'libssh',\n",
    "    'libxml2', 'pcre2',\n",
    "    'proj4', 're2',\n",
    "    'sqlite3', 'vorbis',\n",
    "    'woff2', 'wpantund'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_project = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for \"boringssl\" from \"c-ares\"\n",
      "Getting data for \"boringssl\" from \"freetype2\"\n",
      "Getting data for \"boringssl\" from \"guetzli\"\n",
      "Getting data for \"boringssl\" from \"harfbuzz\"\n",
      "Getting data for \"boringssl\" from \"lcms\"\n",
      "Getting data for \"boringssl\" from \"libpng\"\n",
      "Getting data for \"boringssl\" from \"libssh\"\n",
      "Getting data for \"boringssl\" from \"libxml2\"\n",
      "Getting data for \"boringssl\" from \"pcre2\"\n",
      "Getting data for \"boringssl\" from \"proj4\"\n",
      "Getting data for \"boringssl\" from \"re2\"\n",
      "Getting data for \"boringssl\" from \"sqlite3\"\n",
      "Getting data for \"boringssl\" from \"vorbis\"\n",
      "Getting data for \"boringssl\" from \"woff2\"\n",
      "Getting data for \"boringssl\" from \"wpantund\"\n"
     ]
    }
   ],
   "source": [
    "prefix_np, postfix_np, label_np, label_len_np = data.getTrainData(proj_list, proj_list[target_project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prefix, test_postfix, test_label, test_label_len = data.getTestData(proj_list[target_project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix, val_prefix, train_postfix, val_postfix, train_label, val_label = train_test_split(\n",
    "    prefix_np, postfix_np, label_np, test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader =\\\n",
    "    dl.data_loader(\n",
    "        train_prefix, train_postfix,\n",
    "        val_prefix, val_postfix,\n",
    "        test_prefix, test_postfix,\n",
    "        train_label, val_label, test_label,\n",
    "        batch_size=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('../tensorboard/developing/tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretraied_model as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# set parameters here\n",
    "# ====================\n",
    "\n",
    "title = proj_list[target_project] + '_developing1'\n",
    "epochs = 40\n",
    "\n",
    "embed_dim = 128\n",
    "max_len, source_code_tokens, token_choices = data.getInfo()\n",
    "pretrained_token2vec = pm.load_pretrained_model(source_code_tokens, embed_dim)\n",
    "pretrained_token2vec = torch.tensor(pretrained_token2vec)\n",
    "\n",
    "\n",
    "input_size = max_len\n",
    "hidden_size = 200\n",
    "num_classes = max(token_choices) + 2\n",
    "rnn_layers = 1\n",
    "\n",
    "num_filters = [100, 200, 100]\n",
    "kernel_sizes = [15, 21, 114]\n",
    "\n",
    "dropout = 0.0\n",
    "\n",
    "learning_rate = 0.001\n",
    "# weight_decay = 1e-4\n",
    "weight_decay = 0\n",
    "\n",
    "model_name = \"RNN\"\n",
    "optim_name = \"Adam\"\n",
    "loss_fn_name = \"CEL\"\n",
    "\n",
    "pretrained_model = pretrained_token2vec\n",
    "freeze_embedding = False,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
