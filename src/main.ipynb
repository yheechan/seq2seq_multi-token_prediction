{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now\n",
    "proj_list = [\n",
    "    'boringssl', 'c-ares',\n",
    "    'freetype2', 'guetzli',\n",
    "    'harfbuzz', 'lcms',\n",
    "    'libarchive', 'libpng',\n",
    "    'libssh', 'libxml2',\n",
    "    'pcre2', 'proj4',\n",
    "    're2', 'sqlite3',\n",
    "    'vorbis', 'woff2',\n",
    "    'wpantund'\n",
    "]\n",
    "\n",
    "# b4\n",
    "proj_list = [\n",
    "    'boringssl', 'c-ares',\n",
    "    'freetype2', 'guetzli',\n",
    "    'harfbuzz', 'lcms',\n",
    "    'libpng', 'libssh',\n",
    "    'libxml2', 'pcre2',\n",
    "    'proj4', 're2',\n",
    "    'sqlite3', 'vorbis',\n",
    "    'woff2', 'wpantund'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_project = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch, gc\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import timeit\n",
    "\n",
    "import data\n",
    "import data_loader as dl\n",
    "import initializer as init\n",
    "import trainer\n",
    "import tester\n",
    "# import predictor\n",
    "import model_util as mu\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for \"boringssl\" from \"boringssl\"\n",
      "Getting data for \"boringssl\" from \"c-ares\"\n",
      "Getting data for \"boringssl\" from \"freetype2\"\n",
      "Getting data for \"boringssl\" from \"guetzli\"\n",
      "Getting data for \"boringssl\" from \"harfbuzz\"\n",
      "Getting data for \"boringssl\" from \"lcms\"\n",
      "Getting data for \"boringssl\" from \"libpng\"\n",
      "Getting data for \"boringssl\" from \"libssh\"\n",
      "Getting data for \"boringssl\" from \"libxml2\"\n",
      "Getting data for \"boringssl\" from \"pcre2\"\n",
      "Getting data for \"boringssl\" from \"proj4\"\n",
      "Getting data for \"boringssl\" from \"re2\"\n",
      "Getting data for \"boringssl\" from \"sqlite3\"\n",
      "Getting data for \"boringssl\" from \"vorbis\"\n",
      "Getting data for \"boringssl\" from \"woff2\"\n",
      "Getting data for \"boringssl\" from \"wpantund\"\n"
     ]
    }
   ],
   "source": [
    "# get all data exept target project\n",
    "prefix_np, postfix_np, label_np, label_len_np = data.getTrainData(proj_list, proj_list[target_project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target project data\n",
    "test_prefix, test_postfix, test_label, test_label_len = data.getTestData(proj_list[target_project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix, val_prefix, train_postfix, val_postfix, train_label, val_label = train_test_split(\n",
    "    prefix_np, postfix_np, label_np, test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader =\\\n",
    "    dl.data_loader(\n",
    "        train_prefix, train_postfix,\n",
    "        val_prefix, val_postfix,\n",
    "        test_prefix, test_postfix,\n",
    "        train_label, val_label, test_label,\n",
    "        batch_size=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_title = 'webModel2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('../tensorboard/'+overall_title+'/tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# set parameters here\n",
    "# ====================\n",
    "\n",
    "title = proj_list[target_project] + '_' + overall_title + '_3'\n",
    "epochs = 40\n",
    "\n",
    "max_len, source_code_tokens, token_choices = data.getInfo()\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4 \n",
    "\n",
    "embed_dim = 100\n",
    "hidden_size = 200\n",
    "n_layers = 1\n",
    "output_size = max(token_choices) + 1\n",
    "dropout = 0.5\n",
    "max_length = max_len\n",
    "input_size = max(token_choices) + 1\n",
    "device = device\n",
    "\n",
    "model_name = \"seq2seq\"\n",
    "optim_name = \"Adam\"\n",
    "loss_fn_name = \"CEL\"\n",
    "\n",
    "teacher_forcing_ratio = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arise/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "trainer.set_seed(42)\n",
    "\n",
    "loss_fn, prefix_pack, postfix_pack, attn_pack = init.initialize_model(\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    n_layers=n_layers,\n",
    "    output_size=output_size,\n",
    "    dropout=dropout,\n",
    "    max_length=max_length,\n",
    "    input_size=input_size,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  | Train Acc  | Val Loss | Val Acc | Elapsed\n",
      "--------------------------------------------------------------------------------\n",
      "   1    |   6.300175   | 93.946492  | 9.668332 | 90.48  | 237.57\n",
      "   2    |   5.623495   | 95.724905  | 9.549261 | 91.31  | 242.21\n",
      "   3    |   5.518221   | 96.094107  | 9.235161 | 91.84  | 235.91\n",
      "   4    |   5.459836   | 96.297321  | 9.025065 | 92.01  | 242.40\n",
      "   5    |   5.419937   | 96.441176  | 8.893991 | 92.33  | 241.24\n",
      "   6    |   5.390042   | 96.550546  | 8.797735 | 92.37  | 238.65\n",
      "   7    |   5.365393   | 96.647311  | 8.720750 | 92.52  | 243.70\n",
      "   8    |   5.344805   | 96.726071  | 8.761809 | 92.57  | 236.19\n",
      "   9    |   5.326615   | 96.800273  | 8.627928 | 92.84  | 241.08\n",
      "  10    |   5.310503   | 96.860042  | 8.619812 | 92.77  | 244.28\n",
      "  11    |   5.294668   | 96.926691  | 8.531387 | 92.96  | 237.36\n",
      "  12    |   5.281505   | 96.979485  | 8.482926 | 92.89  | 242.91\n",
      "  13    |   5.269362   | 97.026870  | 8.536971 | 93.09  | 237.39\n",
      "  14    |   5.257533   | 97.071334  | 8.478888 | 93.12  | 240.90\n",
      "  15    |   5.245195   | 97.120819  | 8.403996 | 93.10  | 239.11\n",
      "  16    |   5.234760   | 97.164107  | 8.489064 | 93.24  | 235.37\n",
      "  17    |   5.225051   | 97.202185  | 8.366916 | 93.31  | 236.94\n",
      "  18    |   5.214310   | 97.250242  | 8.367628 | 93.33  | 241.41\n",
      "  19    |   5.205554   | 97.285137  | 8.365671 | 93.40  | 243.62\n",
      "  20    |   5.196733   | 97.313792  | 8.335944 | 93.20  | 236.16\n",
      "  21    |   5.189221   | 97.346975  | 8.245291 | 93.51  | 241.29\n",
      "  22    |   5.181031   | 97.379517  | 8.233664 | 93.37  | 242.00\n",
      "  23    |   5.172843   | 97.412500  | 8.231008 | 93.61  | 236.41\n",
      "  24    |   5.164775   | 97.446639  | 8.190684 | 93.44  | 238.19\n",
      "  25    |   5.159161   | 97.462794  | 8.220128 | 93.53  | 243.08\n",
      "  26    |   5.151521   | 97.491964  | 8.179471 | 93.64  | 242.93\n",
      "  27    |   5.145160   | 97.523120  | 8.144483 | 93.60  | 235.61\n",
      "  28    |   5.139398   | 97.546555  | 8.154917 | 93.77  | 240.62\n",
      "  29    |   5.133177   | 97.568088  | 8.123478 | 93.78  | 243.74\n",
      "  30    |   5.128137   | 97.589412  | 8.193339 | 93.74  | 236.45\n",
      "  31    |   5.121513   | 97.617836  | 8.236709 | 93.85  | 239.63\n",
      "  32    |   5.116717   | 97.633519  | 8.043794 | 93.74  | 241.60\n",
      "  33    |   5.112256   | 97.650945  | 8.208479 | 93.96  | 236.45\n",
      "  34    |   5.106488   | 97.674307  | 8.015503 | 93.92  | 240.66\n",
      "  35    |   5.101916   | 97.692374  | 8.083224 | 93.97  | 241.76\n",
      "  36    |   5.097334   | 97.713876  | 8.001530 | 93.98  | 235.16\n",
      "  37    |   5.093501   | 97.721817  | 8.063774 | 93.99  | 240.72\n",
      "  38    |   5.088644   | 97.745294  | 8.110196 | 94.07  | 240.40\n",
      "  39    |   5.085642   | 97.755221  | 7.987873 | 94.02  | 237.45\n",
      "  40    |   5.080355   | 97.777384  | 8.024203 | 94.04  | 241.31\n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 94.07%.\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "trainer.train(\n",
    "    epochs=epochs,\n",
    "    title=title,\n",
    "    writer=writer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn,\n",
    "    prefix_pack=prefix_pack,\n",
    "    postfix_pack=postfix_pack,\n",
    "    attn_pack=attn_pack,\n",
    "    teacher_forcing_ratio=teacher_forcing_ratio\n",
    ")\n",
    "\n",
    "end_time = (timeit.default_timer() - start_time) / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.saveModel(overall_title, title, prefix_pack, postfix_pack, attn_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_pack, postfix_pack, attn_pack = mu.getModel(overall_title, title)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  7.628797934413072\n",
      "test acc:  94.58054474708172\n"
     ]
    }
   ],
   "source": [
    "loss, acc = tester.test(\n",
    "    test_dataloader=test_dataloader,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn,\n",
    "    prefix_pack=prefix_pack,\n",
    "    postfix_pack=postfix_pack,\n",
    "    attn_pack=attn_pack\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stat/'+overall_title, 'a') as f:\n",
    "        text = title + '\\t |\\tloss: ' + str(loss) + '\\t |\\tacc: ' + str(acc) + '\\t |\\t time: ' + str(round(end_time, 3)) + ' min\\n'\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu.graphModel(train_dataloader, model, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
