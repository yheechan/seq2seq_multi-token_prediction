{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version2\n",
    "proj_list = [\n",
    "    'boringssl', 'c-ares',\n",
    "    'freetype2', 'guetzli',\n",
    "    'harfbuzz', 'lcms',\n",
    "    'libarchive', 'libpng',\n",
    "    'libssh', 'libxml2',\n",
    "    'pcre2', 'proj4',\n",
    "    're2', 'sqlite3',\n",
    "    'vorbis', 'woff2',\n",
    "    'wpantund'\n",
    "]\n",
    "\n",
    "# version3\n",
    "proj_list = [\n",
    "    'boringssl', 'c-ares',\n",
    "    'freetype2', 'guetzli',\n",
    "    'harfbuzz', 'lcms',\n",
    "    'libpng', 'libssh',\n",
    "    'libxml2', 'pcre2',\n",
    "    'proj4', 're2',\n",
    "    'sqlite3', 'vorbis',\n",
    "    'woff2', 'wpantund'\n",
    "]\n",
    "\n",
    "version = 'version4'\n",
    "proj_list = [\n",
    "    'total_aspell', 'total_boringssl', 'total_c-ares', 'total_exiv2',\n",
    "    'total_freetype2', 'total_grok', 'total_guetzli', 'total_harfbuzz',\n",
    "    'total_lcms', 'total_libarchive', 'total_libexif', 'total_libhtp',\n",
    "    'total_libpng', 'total_libsndfile', 'total_libssh', 'total_libxml2',\n",
    "    'total_ndpi', 'total_openthread', 'total_pcre2', 'total_proj4',\n",
    "    'total_re2', 'total_sqlite3', 'total_usrsctp', 'total_vorbis',\n",
    "    'total_woff2', 'total_wpantund', 'total_yara', 'total_zstd'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_project = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch, gc\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import timeit\n",
    "\n",
    "import data\n",
    "import data_loader as dl\n",
    "import initializer as init\n",
    "import trainer\n",
    "import tester\n",
    "# import predictor\n",
    "import model_util as mu\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for \"total_aspell\" from \"total_aspell\"\n",
      "Getting data for \"total_aspell\" from \"total_boringssl\"\n",
      "Getting data for \"total_aspell\" from \"total_c-ares\"\n",
      "Getting data for \"total_aspell\" from \"total_exiv2\"\n",
      "Getting data for \"total_aspell\" from \"total_freetype2\"\n",
      "Getting data for \"total_aspell\" from \"total_grok\"\n",
      "Getting data for \"total_aspell\" from \"total_guetzli\"\n",
      "Getting data for \"total_aspell\" from \"total_harfbuzz\"\n",
      "Getting data for \"total_aspell\" from \"total_lcms\"\n",
      "Getting data for \"total_aspell\" from \"total_libarchive\"\n",
      "Getting data for \"total_aspell\" from \"total_libexif\"\n",
      "Getting data for \"total_aspell\" from \"total_libhtp\"\n",
      "Getting data for \"total_aspell\" from \"total_libpng\"\n",
      "Getting data for \"total_aspell\" from \"total_libsndfile\"\n",
      "Getting data for \"total_aspell\" from \"total_libssh\"\n",
      "Getting data for \"total_aspell\" from \"total_libxml2\"\n",
      "Getting data for \"total_aspell\" from \"total_ndpi\"\n",
      "Getting data for \"total_aspell\" from \"total_openthread\"\n",
      "Getting data for \"total_aspell\" from \"total_pcre2\"\n",
      "Getting data for \"total_aspell\" from \"total_proj4\"\n",
      "Getting data for \"total_aspell\" from \"total_re2\"\n",
      "Getting data for \"total_aspell\" from \"total_sqlite3\"\n",
      "Getting data for \"total_aspell\" from \"total_usrsctp\"\n",
      "Getting data for \"total_aspell\" from \"total_vorbis\"\n",
      "Getting data for \"total_aspell\" from \"total_woff2\"\n",
      "Getting data for \"total_aspell\" from \"total_wpantund\"\n",
      "Getting data for \"total_aspell\" from \"total_yara\"\n",
      "Getting data for \"total_aspell\" from \"total_zstd\"\n"
     ]
    }
   ],
   "source": [
    "# get all data exept target project\n",
    "prefix_np, postfix_np, label_np, label_len_np = data.getTrainData(proj_list, proj_list[target_project], version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target project data\n",
    "# test_prefix, test_postfix, test_label, test_label_len = data.getTestData(proj_list[target_project], version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide train & test\n",
    "train_prefix, test_prefix, train_postfix, test_postfix, train_label, test_label = train_test_split(\n",
    "    prefix_np, postfix_np, label_np, test_size = 0.2, random_state = 43\n",
    ")\n",
    "\n",
    "# divide train & validation\n",
    "train_prefix, val_prefix, train_postfix, val_postfix, train_label, val_label = train_test_split(\n",
    "    train_prefix, train_postfix, train_label, test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  410806\n",
      "train:  1314579\n",
      "validation:  328645\n"
     ]
    }
   ],
   "source": [
    "print('test: ', len(test_label))\n",
    "print('train: ', len(train_label))\n",
    "print('validation: ', len(val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader =\\\n",
    "    dl.data_loader(\n",
    "        train_prefix, train_postfix,\n",
    "        val_prefix, val_postfix,\n",
    "        test_prefix, test_postfix,\n",
    "        train_label, val_label, test_label,\n",
    "        batch_size=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_title = 'version3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('../tensorboard/'+overall_title+'/tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# set parameters here\n",
    "# ====================\n",
    "\n",
    "title = overall_title + '_01'\n",
    "epochs = 40\n",
    "\n",
    "max_len, source_code_tokens, token_choices = data.getInfo()\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0\n",
    "\n",
    "embed_dim = 100\n",
    "hidden_size = 200\n",
    "n_layers = 1\n",
    "output_size = max(token_choices) + 1\n",
    "dropout = 0.0\n",
    "max_length = max_len\n",
    "input_size = max(token_choices) + 1\n",
    "device = device\n",
    "\n",
    "model_name = \"seq2seq\"\n",
    "optim_name = \"Adam\"\n",
    "loss_fn_name = \"CEL\"\n",
    "\n",
    "teacher_forcing_ratio = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_seed(42)\n",
    "\n",
    "model, loss_fn, optimizer = init.initialize_model(\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    n_layers=n_layers,\n",
    "    output_size=output_size,\n",
    "    dropout=dropout,\n",
    "    max_length=max_length,\n",
    "    input_size=input_size,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  | Train Acc  | Val Loss | Val Acc | Elapsed\n",
      "--------------------------------------------------------------------------------\n",
      "   1    |   0.349649   | 91.386621  | 0.345125 | 91.43  | 420.67\n",
      "   2    |   0.194348   | 94.687268  | 0.286111 | 92.45  | 410.60\n",
      "   3    |   0.165480   | 95.430662  | 0.271827 | 93.12  | 415.86\n",
      "   4    |   0.154132   | 95.772078  | 0.262359 | 93.56  | 414.74\n",
      "   5    |   0.142117   | 96.104193  | 0.264979 | 93.68  | 408.07\n",
      "   6    |   0.136009   | 96.290837  | 0.244227 | 93.95  | 413.36\n",
      "   7    |   0.127757   | 96.508432  | 0.247498 | 94.15  | 406.61\n",
      "   8    |   0.125461   | 96.603577  | 0.226503 | 94.35  | 412.71\n",
      "   9    |   0.117911   | 96.803037  | 0.220454 | 94.44  | 407.17\n",
      "  10    |   0.112779   | 96.955959  | 0.207217 | 94.65  | 410.50\n",
      "  11    |   0.108809   | 97.076537  | 0.216272 | 94.83  | 412.44\n",
      "  12    |   0.103575   | 97.224970  | 0.224589 | 94.94  | 408.99\n",
      "  13    |   0.100172   | 97.323037  | 0.202202 | 94.96  | 411.77\n",
      "  14    |   0.092975   | 97.515205  | 0.200338 | 95.11  | 407.33\n",
      "  15    |   0.088352   | 97.633113  | 0.214269 | 95.06  | 411.75\n",
      "  16    |   0.088431   | 97.656423  | 0.204575 | 95.32  | 407.44\n",
      "  17    |   0.083671   | 97.781712  | 0.204238 | 95.35  | 409.10\n",
      "  18    |   0.080905   | 97.860365  | 0.200351 | 95.40  | 412.40\n",
      "  19    |   0.078559   | 97.931202  | 0.202968 | 95.38  | 408.23\n",
      "  20    |   0.076997   | 97.979391  | 0.196881 | 95.53  | 410.18\n",
      "  21    |   0.072793   | 98.086050  | 0.195223 | 95.57  | 408.43\n",
      "  22    |   0.070460   | 98.152139  | 0.198655 | 95.62  | 412.16\n",
      "  23    |   0.069043   | 98.198813  | 0.196184 | 95.65  | 407.56\n",
      "  24    |   0.071428   | 98.160107  | 0.182175 | 95.68  | 410.36\n",
      "  25    |   0.065889   | 98.291872  | 0.189416 | 95.73  | 407.49\n",
      "  26    |   0.064179   | 98.336560  | 0.198069 | 95.78  | 413.31\n",
      "  27    |   0.060104   | 98.436941  | 0.191872 | 95.77  | 408.29\n",
      "  28    |   0.058748   | 98.475381  | 0.193990 | 95.82  | 408.89\n",
      "  29    |   0.059396   | 98.471796  | 0.189802 | 95.76  | 411.30\n",
      "  30    |   0.057554   | 98.521895  | 0.193085 | 95.86  | 408.90\n",
      "  31    |   0.056468   | 98.549726  | 0.197666 | 95.90  | 410.40\n",
      "  32    |   0.054897   | 98.594863  | 0.192368 | 95.86  | 407.91\n",
      "  33    |   0.055855   | 98.581027  | 0.189265 | 95.86  | 412.63\n",
      "  34    |   0.053284   | 98.640830  | 0.189363 | 95.96  | 408.36\n",
      "  35    |   0.052099   | 98.672443  | 0.197242 | 95.95  | 409.50\n",
      "  36    |   0.051948   | 98.685449  | 0.188061 | 95.91  | 411.21\n",
      "  37    |   0.050624   | 98.717237  | 0.201817 | 96.03  | 409.67\n",
      "  38    |   0.049201   | 98.755365  | 0.191249 | 96.00  | 411.39\n",
      "  39    |   0.048535   | 98.775479  | 0.196859 | 96.01  | 407.64\n",
      "  40    |   0.046875   | 98.810974  | 0.200613 | 95.97  | 410.31\n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 96.03%.\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "trainer.train(\n",
    "    epochs=epochs,\n",
    "    title=title,\n",
    "    writer=writer,\n",
    "    teacher_forcing_ratio=teacher_forcing_ratio,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "end_time = (timeit.default_timer() - start_time) / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.saveModel(overall_title, title, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySeq2Seq(\n",
      "  (prefixEncoder): Encoder(\n",
      "    (embedding): Embedding(155, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postfixEncoder): Encoder(\n",
      "    (embedding): Embedding(155, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(155, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (attn): Attention(\n",
      "    (fc): Linear(in_features=800, out_features=155, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = mu.getModel(overall_title, title)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  0.19950869256846335\n",
      "test acc:  95.99090243902438\n"
     ]
    }
   ],
   "source": [
    "loss, acc = tester.test(\n",
    "    test_dataloader=test_dataloader,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stat/'+overall_title, 'a') as f:\n",
    "        text = title + '\\t |\\tloss: ' + str(loss) + '\\t |\\tacc: ' + str(acc) + '\\t |\\t time: ' + str(round(end_time, 3)) + ' min\\n'\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded model graph to tensorboard!\n"
     ]
    }
   ],
   "source": [
    "mu.graphModel(train_dataloader, model, writer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
